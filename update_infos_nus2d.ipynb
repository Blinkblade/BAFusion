{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import time\n",
    "from os import path as osp\n",
    "from pathlib import Path\n",
    "\n",
    "import mmengine\n",
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "from mmdet3d.datasets.convert_utils import (convert_annos,\n",
    "                                            get_kitti_style_2d_boxes,\n",
    "                                            get_nuscenes_2d_boxes)\n",
    "from mmdet3d.datasets.utils import convert_quaternion_to_matrix\n",
    "from mmdet3d.structures import points_cam2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_instance():\n",
    "    \"\"\"Empty annotation for single instance.\"\"\"\n",
    "    instance = dict(\n",
    "        # (list[float], required): list of 4 numbers representing\n",
    "        # the bounding box of the instance, in (x1, y1, x2, y2) order.\n",
    "        bbox=None,\n",
    "        # (int, required): an integer in the range\n",
    "        # [0, num_categories-1] representing the category label.\n",
    "        bbox_label=None,\n",
    "        #  (list[float], optional): list of 7 (or 9) numbers representing\n",
    "        #  the 3D bounding box of the instance,\n",
    "        #  in [x, y, z, w, h, l, yaw]\n",
    "        #  (or [x, y, z, w, h, l, yaw, vx, vy]) order.\n",
    "        bbox_3d=None,\n",
    "        # (bool, optional): Whether to use the\n",
    "        # 3D bounding box during training.\n",
    "        bbox_3d_isvalid=None,\n",
    "        # (int, optional): 3D category label\n",
    "        # (typically the same as label).\n",
    "        bbox_label_3d=None,\n",
    "        # (float, optional): Projected center depth of the\n",
    "        # 3D bounding box compared to the image plane.\n",
    "        depth=None,\n",
    "        #  (list[float], optional): Projected\n",
    "        #  2D center of the 3D bounding box.\n",
    "        center_2d=None,\n",
    "        # (int, optional): Attribute labels\n",
    "        # (fine-grained labels such as stopping, moving, ignore, crowd).\n",
    "        attr_label=None,\n",
    "        # (int, optional): The number of LiDAR\n",
    "        # points in the 3D bounding box.\n",
    "        num_lidar_pts=None,\n",
    "        # (int, optional): The number of Radar\n",
    "        # points in the 3D bounding box.\n",
    "        num_radar_pts=None,\n",
    "        # (int, optional): Difficulty level of\n",
    "        # detecting the 3D bounding box.\n",
    "        difficulty=None,\n",
    "        unaligned_bbox_3d=None,\n",
    "        \n",
    "        # 构建annotation需要的键值\n",
    "        gt_bboxes = None,\n",
    "        gt_labels = None,\n",
    "\n",
    "        )\n",
    "    return instance\n",
    "\n",
    "\n",
    "def get_empty_multicamera_instances(camera_types):\n",
    "\n",
    "    cam_instance = dict()\n",
    "    for cam_type in camera_types:\n",
    "        cam_instance[cam_type] = None\n",
    "    return cam_instance\n",
    "\n",
    "\n",
    "def get_empty_lidar_points():\n",
    "    lidar_points = dict(\n",
    "        # (int, optional) : Number of features for each point.\n",
    "        num_pts_feats=None,\n",
    "        # (str, optional): Path of LiDAR data file.\n",
    "        lidar_path=None,\n",
    "        # (list[list[float]], optional): Transformation matrix\n",
    "        # from lidar to ego-vehicle\n",
    "        # with shape [4, 4].\n",
    "        # (Referenced camera coordinate system is ego in KITTI.)\n",
    "        lidar2ego=None,\n",
    "    )\n",
    "    return lidar_points\n",
    "\n",
    "\n",
    "def get_empty_radar_points():\n",
    "    radar_points = dict(\n",
    "        # (int, optional) : Number of features for each point.\n",
    "        num_pts_feats=None,\n",
    "        # (str, optional): Path of RADAR data file.\n",
    "        radar_path=None,\n",
    "        # Transformation matrix from lidar to\n",
    "        # ego-vehicle with shape [4, 4].\n",
    "        # (Referenced camera coordinate system is ego in KITTI.)\n",
    "        radar2ego=None,\n",
    "    )\n",
    "    return radar_points\n",
    "\n",
    "\n",
    "def get_empty_img_info():\n",
    "    img_info = dict(\n",
    "        # (str, required): the path to the image file.\n",
    "        img_path=None,\n",
    "        # (int) The height of the image.\n",
    "        height=None,\n",
    "        # (int) The width of the image.\n",
    "        width=None,\n",
    "        # (str, optional): Path of the depth map file\n",
    "        depth_map=None,\n",
    "        # (list[list[float]], optional) : Transformation\n",
    "        # matrix from camera to image with\n",
    "        # shape [3, 3], [3, 4] or [4, 4].\n",
    "        cam2img=None,\n",
    "        # (list[list[float]]): Transformation matrix from lidar\n",
    "        # or depth to image with shape [4, 4].\n",
    "        lidar2img=None,\n",
    "        # (list[list[float]], optional) : Transformation\n",
    "        # matrix from camera to ego-vehicle\n",
    "        # with shape [4, 4].\n",
    "        cam2ego=None)\n",
    "    return img_info\n",
    "\n",
    "def get_single_image_sweep(camera_types):\n",
    "    single_image_sweep = dict(\n",
    "        # (float, optional) : Timestamp of the current frame.\n",
    "        timestamp=None,\n",
    "        # (list[list[float]], optional) : Transformation matrix\n",
    "        # from ego-vehicle to the global\n",
    "        ego2global=None)\n",
    "    # (dict): Information of images captured by multiple cameras\n",
    "    images = dict()\n",
    "    for cam_type in camera_types:\n",
    "        images[cam_type] = get_empty_img_info()\n",
    "    single_image_sweep['images'] = images\n",
    "    return single_image_sweep\n",
    "\n",
    "\n",
    "def get_single_lidar_sweep():\n",
    "    single_lidar_sweep = dict(\n",
    "        # (float, optional) : Timestamp of the current frame.\n",
    "        timestamp=None,\n",
    "        # (list[list[float]], optional) : Transformation matrix\n",
    "        # from ego-vehicle to the global\n",
    "        ego2global=None,\n",
    "        # (dict): Information of images captured by multiple cameras\n",
    "        lidar_points=get_empty_lidar_points())\n",
    "    return single_lidar_sweep\n",
    "\n",
    "def get_empty_standard_data_info(\n",
    "        camera_types=['CAM0', 'CAM1', 'CAM2', 'CAM3', 'CAM4']):\n",
    "\n",
    "    data_info = dict(\n",
    "        # (str): Sample id of the frame.\n",
    "        sample_idx=None,\n",
    "        # (str, optional): '000010'\n",
    "        token=None,\n",
    "        **get_single_image_sweep(camera_types),\n",
    "        # (dict, optional): dict contains information\n",
    "        # of LiDAR point cloud frame.\n",
    "        lidar_points=get_empty_lidar_points(),\n",
    "        # (dict, optional) Each dict contains\n",
    "        # information of Radar point cloud frame.\n",
    "        radar_points=get_empty_radar_points(),\n",
    "        # (list[dict], optional): Image sweeps data.\n",
    "        image_sweeps=[],\n",
    "        lidar_sweeps=[],\n",
    "        instances=[],\n",
    "        # (list[dict], optional): Required by object\n",
    "        # detection, instance  to be ignored during training.\n",
    "        instances_ignore=[],\n",
    "        # (str, optional): Path of semantic labels for each point.\n",
    "        pts_semantic_mask_path=None,\n",
    "        # (str, optional): Path of instance labels for each point.\n",
    "        pts_instance_mask_path=None)\n",
    "    return data_info\n",
    "\n",
    "\n",
    "def clear_instance_unused_keys(instance):\n",
    "    keys = list(instance.keys())\n",
    "    for k in keys:\n",
    "        if instance[k] is None:\n",
    "            del instance[k]\n",
    "    return instance\n",
    "\n",
    "\n",
    "def clear_data_info_unused_keys(data_info):\n",
    "    keys = list(data_info.keys())\n",
    "    empty_flag = True\n",
    "    for key in keys:\n",
    "        # we allow no annotations in datainfo\n",
    "        if key in ['instances', 'cam_sync_instances', 'cam_instances']:\n",
    "            empty_flag = False\n",
    "            continue\n",
    "        if isinstance(data_info[key], list):\n",
    "            if len(data_info[key]) == 0:\n",
    "                del data_info[key]\n",
    "            else:\n",
    "                empty_flag = False\n",
    "        elif data_info[key] is None:\n",
    "            del data_info[key]\n",
    "        elif isinstance(data_info[key], dict):\n",
    "            _, sub_empty_flag = clear_data_info_unused_keys(data_info[key])\n",
    "            if sub_empty_flag is False:\n",
    "                empty_flag = False\n",
    "            else:\n",
    "                # sub field is empty\n",
    "                del data_info[key]\n",
    "        else:\n",
    "            empty_flag = False\n",
    "\n",
    "    return data_info, empty_flag\n",
    "\n",
    "\n",
    "def generate_nuscenes_camera_instances(info, nusc):\n",
    "\n",
    "    # get bbox annotations for camera\n",
    "    camera_types = [\n",
    "        'CAM_FRONT',\n",
    "        'CAM_FRONT_RIGHT',\n",
    "        'CAM_FRONT_LEFT',\n",
    "        'CAM_BACK',\n",
    "        'CAM_BACK_LEFT',\n",
    "        'CAM_BACK_RIGHT',\n",
    "    ]\n",
    "\n",
    "    empty_multicamera_instance = get_empty_multicamera_instances(camera_types)\n",
    "\n",
    "    for cam in camera_types:\n",
    "        cam_info = info['cams'][cam]\n",
    "        # list[dict]\n",
    "        ann_infos = get_nuscenes_2d_boxes(\n",
    "            nusc,\n",
    "            cam_info['sample_data_token'],\n",
    "            visibilities=['', '1', '2', '3', '4'])\n",
    "        empty_multicamera_instance[cam] = ann_infos\n",
    "\n",
    "    return empty_multicamera_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 罪魁祸首！！这一步只使用了3D annotation信息, 把所有2D信息都滤除了！\n",
    "def update_nuscenes_infos2D(pkl_path, out_dir, dataroot='./data/nuscenes'):\n",
    "    camera_types = [\n",
    "        'CAM_FRONT',\n",
    "        'CAM_FRONT_RIGHT',\n",
    "        'CAM_FRONT_LEFT',\n",
    "        'CAM_BACK',\n",
    "        'CAM_BACK_LEFT',\n",
    "        'CAM_BACK_RIGHT',\n",
    "    ]\n",
    "    print(f'{pkl_path} will be modified.')\n",
    "    if out_dir in pkl_path:\n",
    "        print(f'Warning, you may overwriting '\n",
    "              f'the original data {pkl_path}.')\n",
    "    print(f'Reading from input file: {pkl_path}.')\n",
    "    data_list = mmengine.load(pkl_path)\n",
    "    METAINFO = {\n",
    "        'classes':\n",
    "        ('car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n",
    "         'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'),\n",
    "    }\n",
    "    # 可以使用mini数据集进行简单测试\n",
    "    # mini metadata\n",
    "    # version = dict()\n",
    "    # version[\"version\"] = 'v1.0-mini'\n",
    "    # data_list['metadata'] = version\n",
    "    \n",
    "    nusc = NuScenes(\n",
    "        version=data_list['metadata']['version'],\n",
    "        # dataroot='./data/nuscenes',\n",
    "        dataroot=dataroot,\n",
    "        verbose=True)\n",
    "\n",
    "    print('Start updating:')\n",
    "    converted_list = []\n",
    "    for i, ori_info_dict in enumerate(\n",
    "            mmengine.track_iter_progress(data_list['infos'])):\n",
    "        temp_data_info = get_empty_standard_data_info(\n",
    "            camera_types=camera_types)\n",
    "        temp_data_info['sample_idx'] = i\n",
    "        temp_data_info['token'] = ori_info_dict['token']\n",
    "        temp_data_info['ego2global'] = convert_quaternion_to_matrix(\n",
    "            ori_info_dict['ego2global_rotation'],\n",
    "            ori_info_dict['ego2global_translation'])\n",
    "        temp_data_info['lidar_points']['num_pts_feats'] = ori_info_dict.get(\n",
    "            'num_features', 5)\n",
    "        temp_data_info['lidar_points']['lidar_path'] = Path(\n",
    "            ori_info_dict['lidar_path']).name\n",
    "        temp_data_info['lidar_points'][\n",
    "            'lidar2ego'] = convert_quaternion_to_matrix(\n",
    "                ori_info_dict['lidar2ego_rotation'],\n",
    "                ori_info_dict['lidar2ego_translation'])\n",
    "        # bc-breaking: Timestamp has divided 1e6 in pkl infos.\n",
    "        temp_data_info['timestamp'] = ori_info_dict['timestamp'] / 1e6\n",
    "        for ori_sweep in ori_info_dict['sweeps']:\n",
    "            temp_lidar_sweep = get_single_lidar_sweep()\n",
    "            temp_lidar_sweep['lidar_points'][\n",
    "                'lidar2ego'] = convert_quaternion_to_matrix(\n",
    "                    ori_sweep['sensor2ego_rotation'],\n",
    "                    ori_sweep['sensor2ego_translation'])\n",
    "            temp_lidar_sweep['ego2global'] = convert_quaternion_to_matrix(\n",
    "                ori_sweep['ego2global_rotation'],\n",
    "                ori_sweep['ego2global_translation'])\n",
    "            lidar2sensor = np.eye(4)\n",
    "            rot = ori_sweep['sensor2lidar_rotation']\n",
    "            trans = ori_sweep['sensor2lidar_translation']\n",
    "            lidar2sensor[:3, :3] = rot.T\n",
    "            lidar2sensor[:3, 3:4] = -1 * np.matmul(rot.T, trans.reshape(3, 1))\n",
    "            temp_lidar_sweep['lidar_points'][\n",
    "                'lidar2sensor'] = lidar2sensor.astype(np.float32).tolist()\n",
    "            temp_lidar_sweep['timestamp'] = ori_sweep['timestamp'] / 1e6\n",
    "            temp_lidar_sweep['lidar_points']['lidar_path'] = ori_sweep[\n",
    "                'data_path']\n",
    "            temp_lidar_sweep['sample_data_token'] = ori_sweep[\n",
    "                'sample_data_token']\n",
    "            temp_data_info['lidar_sweeps'].append(temp_lidar_sweep)\n",
    "        temp_data_info['images'] = {}\n",
    "        for cam in ori_info_dict['cams']:\n",
    "            empty_img_info = get_empty_img_info()\n",
    "            empty_img_info['img_path'] = Path(\n",
    "                ori_info_dict['cams'][cam]['data_path']).name\n",
    "            empty_img_info['cam2img'] = ori_info_dict['cams'][cam][\n",
    "                'cam_intrinsic'].tolist()\n",
    "            empty_img_info['sample_data_token'] = ori_info_dict['cams'][cam][\n",
    "                'sample_data_token']\n",
    "            # bc-breaking: Timestamp has divided 1e6 in pkl infos.\n",
    "            empty_img_info[\n",
    "                'timestamp'] = ori_info_dict['cams'][cam]['timestamp'] / 1e6\n",
    "            empty_img_info['cam2ego'] = convert_quaternion_to_matrix(\n",
    "                ori_info_dict['cams'][cam]['sensor2ego_rotation'],\n",
    "                ori_info_dict['cams'][cam]['sensor2ego_translation'])\n",
    "            lidar2sensor = np.eye(4)\n",
    "            rot = ori_info_dict['cams'][cam]['sensor2lidar_rotation']\n",
    "            trans = ori_info_dict['cams'][cam]['sensor2lidar_translation']\n",
    "            lidar2sensor[:3, :3] = rot.T\n",
    "            lidar2sensor[:3, 3:4] = -1 * np.matmul(rot.T, trans.reshape(3, 1))\n",
    "            empty_img_info['lidar2cam'] = lidar2sensor.astype(\n",
    "                np.float32).tolist()\n",
    "            temp_data_info['images'][cam] = empty_img_info\n",
    "        ignore_class_name = set()\n",
    "        # 由于aav2的作者每个3dbbox只对应一个2d bbox, gt bbox的顺序和 gt bbox 2d的顺序是一一对应的\n",
    "        # 我们可以同步在这里修改\n",
    "        if 'gt_boxes' in ori_info_dict:\n",
    "            # 本次采样的实例数量,即检测到的Object数量\n",
    "            num_instances = ori_info_dict['gt_boxes'].shape[0]\n",
    "            for i in range(num_instances):\n",
    "                empty_instance = get_empty_instance()\n",
    "                empty_instance['bbox_3d'] = ori_info_dict['gt_boxes'][\n",
    "                    i, :].tolist()\n",
    "                \n",
    "                # 同时录入对应的2d bbox, 由于在生成时已经完成了11对应，所有有多少3D BBOX就有多少2D BBOX\n",
    "                # empty_instance['bbox'] = ori_info_dict['gt_boxes_2d'][\n",
    "                #     i, :].tolist()\n",
    "                # annotation要求\n",
    "                empty_instance['gt_bboxes'] = ori_info_dict['gt_boxes_2d'][\n",
    "                    i, :].tolist()\n",
    "                \n",
    "                if ori_info_dict['gt_names'][i] in METAINFO['classes']:\n",
    "                    empty_instance['bbox_label'] = METAINFO['classes'].index(\n",
    "                        ori_info_dict['gt_names'][i])\n",
    "                else:\n",
    "                    ignore_class_name.add(ori_info_dict['gt_names'][i])\n",
    "                    empty_instance['bbox_label'] = -1\n",
    "                empty_instance['bbox_label_3d'] = copy.deepcopy(\n",
    "                    empty_instance['bbox_label'])\n",
    "                \n",
    "                # 很显然同一个实例的label 3d 和 label 2d是完全一样的\n",
    "                # empty_instance['bbox_label'] = copy.deepcopy(\n",
    "                #     empty_instance['bbox_label'])\n",
    "                # annotation要求\n",
    "                empty_instance['gt_labels'] = copy.deepcopy(\n",
    "                    empty_instance['bbox_label'])\n",
    "\n",
    "\n",
    "                empty_instance['velocity'] = ori_info_dict['gt_velocity'][\n",
    "                    i, :].tolist()\n",
    "                empty_instance['num_lidar_pts'] = ori_info_dict[\n",
    "                    'num_lidar_pts'][i]\n",
    "                empty_instance['num_radar_pts'] = ori_info_dict[\n",
    "                    'num_radar_pts'][i]\n",
    "                empty_instance['bbox_3d_isvalid'] = ori_info_dict[\n",
    "                    'valid_flag'][i]\n",
    "                empty_instance = clear_instance_unused_keys(empty_instance)\n",
    "                temp_data_info['instances'].append(empty_instance)\n",
    "            temp_data_info[\n",
    "                'cam_instances'] = generate_nuscenes_camera_instances(\n",
    "                    ori_info_dict, nusc)\n",
    "        if 'pts_semantic_mask_path' in ori_info_dict:\n",
    "            temp_data_info['pts_semantic_mask_path'] = Path(\n",
    "                ori_info_dict['pts_semantic_mask_path']).name\n",
    "        temp_data_info, _ = clear_data_info_unused_keys(temp_data_info)\n",
    "        converted_list.append(temp_data_info)\n",
    "    pkl_name = Path(pkl_path).name\n",
    "    out_path = osp.join(out_dir, pkl_name)\n",
    "    print(f'Writing to output file: {out_path}.')\n",
    "    print(f'ignore classes: {ignore_class_name}')\n",
    "\n",
    "    metainfo = dict()\n",
    "    metainfo['categories'] = {k: i for i, k in enumerate(METAINFO['classes'])}\n",
    "    if ignore_class_name:\n",
    "        for ignore_class in ignore_class_name:\n",
    "            metainfo['categories'][ignore_class] = -1\n",
    "    metainfo['dataset'] = 'nuscenes'\n",
    "    metainfo['version'] = data_list['metadata']['version']\n",
    "    metainfo['info_version'] = '1.1'\n",
    "    converted_data_info = dict(metainfo=metainfo, data_list=converted_list)\n",
    "\n",
    "    mmengine.dump(converted_data_info, out_path, 'pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = './data/nuscenes_mini'\n",
    "train_pkl_path = './data/nuscenes_mini/nuscenes_infos_train.pkl'\n",
    "val_pkl_path = './data/nuscenes_mini/nuscenes_infos_val.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/nuscenes_mini/nuscenes_infos_train.pkl will be modified.\n",
      "Warning, you may overwriting the original data ./data/nuscenes_mini/nuscenes_infos_train.pkl.\n",
      "Reading from input file: ./data/nuscenes_mini/nuscenes_infos_train.pkl.\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.434 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n",
      "Start updating:\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 323/323, 15.8 task/s, elapsed: 20s, ETA:     0s\n",
      "Writing to output file: ./data/nuscenes_mini/nuscenes_infos_train.pkl.\n",
      "ignore classes: set()\n"
     ]
    }
   ],
   "source": [
    "update_nuscenes_infos2D(train_pkl_path,dataroot,dataroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
